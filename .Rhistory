# 1.2 Load test dataset
x_test<-read.table(paste(dir_path, "test/X_test.txt", sep = ""),
header = FALSE)
y_test<-read.table(paste(dir_path, "test/y_test.txt", sep = ""),
header = FALSE)
#Get activities from test labels data
test<-cbind(x_test, activities = y_test$V1)
# 1.3 Merge training and test data set
smrt_phne_dataset<-rbind(train, test)
#Delete temporary vectors
rm("x_train", "y_train", "x_test", "y_test", "train", "test")
#========================================================================================================================
# 2. Extracts only the measurements on the mean and standard deviation for each measurement.
# 2.1 Using the features.txt, get the column names for every variable in data set
features<-read.table(paste(dir_path, "/features.txt", sep = ""),
header = FALSE)
# 2.2 Get the column names which have mean or std in it.
col_names<-features$V1[grep("(mean\\(\\))|std\\(\\)", features$V2)]
# 2.3 Subset the data based on the mean and standard deviation for each measurement.
measured_values<-smrt_phne_dataset[c(sapply(col_names, function(x){paste("V", x, sep = "")}), "activities")]
#========================================================================================================================
# 3. Uses descriptive activity names to name the activities in the data set
# 3.1 Load the activity_labels.txt which has the descriptive activity names for each activity
activity_labels<-read.table(paste(dir_path, "/activity_labels.txt", sep = ""),
header = FALSE)
# 3.2 Update activities with values from activity_labels to the main dataset
measured_values$activities<-sapply(measured_values$activities,
function(x){activity_labels$V2[activity_labels$V1==x]})
#========================================================================================================================
# 4. Appropriately labels the data set with descriptive variable names.
# 4.1 Get the descriptive names using the features data frame
library(dplyr)
measure_features<-features[features$V1 %in% col_names,]
# 4.2 Helper function to clean the variable name to appropriate format
name_clean<-function(x) {
x<-as.character(x)
temp_list<-strsplit(x, "\\-")
var_name<-tolower(temp_list[[1]][1])
if (lengths(temp_list)>1){
method<-substr(tolower(temp_list[[1]][2]),1, nchar(temp_list[[1]][2])-2)
var_name<-paste(var_name, method, sep = "_")
}
if (lengths(temp_list)>2){
var_name<-paste(var_name, tolower(temp_list[[1]][3]), sep = "_")
}
var_name
}
# 4.3 Update the column names for measured_values data frame.
library(readr)
iter<-0
detail_names<-c()
for (element in colnames(measured_values)[1:(length(colnames(measured_values)) -1)]) {
ele_no<-parse_number(as.character(element))
iter<- iter + 1
if (ele_no %in% as.numeric(measure_features$V1)) {
variable_name<-name_clean(measure_features$V2[iter])
detail_names<-append(detail_names, variable_name, after = length(detail_names))
} else {print(ele_no)}
}
names(measured_values)[1:length(measured_values)-1] <- detail_names
#Delete temporary vectors
rm("iter", "detail_names", "ele_no", "element", "variable_name", "col_names", "measure_features")
#========================================================================================================================
# 5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable
#    for each activity and each subject.
# 5.1 Load subject data
sub_train<-read.table(paste(dir_path, "train/subject_train.txt", sep = ""),
header = FALSE)
sub_test<-read.table(paste(dir_path, "test/subject_test.txt", sep = ""),
header = FALSE)
subjects<-rbind(sub_train, sub_test)
# 5.2 Include subjects in the measured_values data frame
measured_values<-cbind(measured_values, subjects = subjects$V1)
# 5.3 Get the column_names for every measure variables
measure_var_names<-names(measured_values)[1:(ncol(measured_values)-2)]
# 5.3 Create a new data set with the averages of each variable for each activity and each subject.
measured_averages<-measured_values %>%
group_by(activities, subjects) %>%
summarize_at(measure_var_names, funs(mean(., na.rm = TRUE)))
#Delete temporary vectors
rm("sub_train", "sub_test", "subjects", "measure_var_names", "dir_path")
View(measured_averages)
#========================================================================================================================
colnames(measured_averages)
colnames(measured_averages)
class(measured_averages['fbodygyro_std_x'])
class(measured_averages$tbodyacc_mean_x)
class(measured_averages$fbodyacc_std_y)
class(measured_averages$activities)
class(measured_averages$subjects)
getwd()
# 1. Merges the training and the test sets to create one data set.
# 1.1 Load training dataset
#The absolute path of the data directory
dir_path = "OneDrive/Documents/Getting and Cleaning Data/CourseProject/"
x_train<-read.table(paste(dir_path, "train/X_train.txt", sep = ""),
header = FALSE)
y_train<-read.table(paste(dir_path, "train/y_train.txt", sep = ""),
header = FALSE)
# 1.1 Load training dataset
#The absolute path of the data directory
dir_path = "/OneDrive/Documents/Getting and Cleaning Data/CourseProject/"
x_train<-read.table(paste(dir_path, "train/X_train.txt", sep = ""),
header = FALSE)
y_train<-read.table(paste(dir_path, "train/y_train.txt", sep = ""),
header = FALSE)
# 1.1 Load training dataset
#The absolute path of the data directory
dir_path = "C:/Users/bhara/OneDrive/Documents/Getting and Cleaning Data/CourseProject/"
x_train<-read.table(paste(dir_path, "train/X_train.txt", sep = ""),
header = FALSE)
y_train<-read.table(paste(dir_path, "train/y_train.txt", sep = ""),
header = FALSE)
# 1.1 Load training dataset
#The absolute path of the data directory
dir_path = "OneDrive/Documents/Getting and Cleaning Data/CourseProject/data/"
x_train<-read.table(paste(dir_path, "train/X_train.txt", sep = ""),
header = FALSE)
y_train<-read.table(paste(dir_path, "train/y_train.txt", sep = ""),
header = FALSE)
#========================================================================================================================
# 1. Merges the training and the test sets to create one data set.
# 1.1 Load training dataset
#The absolute path of the data directory
dir_path = "OneDrive/Documents/Getting and Cleaning Data/CourseProject/data/"
x_train<-read.table(paste(dir_path, "train/X_train.txt", sep = ""),
header = FALSE)
y_train<-read.table(paste(dir_path, "train/y_train.txt", sep = ""),
header = FALSE)
#Get activities from training labels data
train<-cbind(x_train, activities = y_train$V1)
# 1.2 Load test dataset
x_test<-read.table(paste(dir_path, "test/X_test.txt", sep = ""),
header = FALSE)
y_test<-read.table(paste(dir_path, "test/y_test.txt", sep = ""),
header = FALSE)
#Get activities from test labels data
test<-cbind(x_test, activities = y_test$V1)
# 1.3 Merge training and test data set
smrt_phne_dataset<-rbind(train, test)
#Delete temporary vectors
rm("x_train", "y_train", "x_test", "y_test", "train", "test")
#========================================================================================================================
# 2. Extracts only the measurements on the mean and standard deviation for each measurement.
# 2.1 Using the features.txt, get the column names for every variable in data set
features<-read.table(paste(dir_path, "/features.txt", sep = ""),
header = FALSE)
# 2.2 Get the column names which have mean or std in it.
col_names<-features$V1[grep("(mean\\(\\))|std\\(\\)", features$V2)]
# 2.3 Subset the data based on the mean and standard deviation for each measurement.
measured_values<-smrt_phne_dataset[c(sapply(col_names, function(x){paste("V", x, sep = "")}), "activities")]
#========================================================================================================================
# 3. Uses descriptive activity names to name the activities in the data set
# 3.1 Load the activity_labels.txt which has the descriptive activity names for each activity
activity_labels<-read.table(paste(dir_path, "/activity_labels.txt", sep = ""),
header = FALSE)
# 3.2 Update activities with values from activity_labels to the main dataset
measured_values$activities<-sapply(measured_values$activities,
function(x){activity_labels$V2[activity_labels$V1==x]})
#========================================================================================================================
# 4. Appropriately labels the data set with descriptive variable names.
# 4.1 Get the descriptive names using the features data frame
library(dplyr)
measure_features<-features[features$V1 %in% col_names,]
# 4.2 Helper function to clean the variable name to appropriate format
name_clean<-function(x) {
x<-as.character(x)
temp_list<-strsplit(x, "\\-")
var_name<-tolower(temp_list[[1]][1])
if (lengths(temp_list)>1){
method<-substr(tolower(temp_list[[1]][2]),1, nchar(temp_list[[1]][2])-2)
var_name<-paste(var_name, method, sep = "_")
}
if (lengths(temp_list)>2){
var_name<-paste(var_name, tolower(temp_list[[1]][3]), sep = "_")
}
var_name
}
# 4.3 Update the column names for measured_values data frame.
library(readr)
iter<-0
detail_names<-c()
for (element in colnames(measured_values)[1:(length(colnames(measured_values)) -1)]) {
ele_no<-parse_number(as.character(element))
iter<- iter + 1
if (ele_no %in% as.numeric(measure_features$V1)) {
variable_name<-name_clean(measure_features$V2[iter])
detail_names<-append(detail_names, variable_name, after = length(detail_names))
} else {print(ele_no)}
}
names(measured_values)[1:length(measured_values)-1] <- detail_names
#Delete temporary vectors
rm("iter", "detail_names", "ele_no", "element", "variable_name", "col_names", "measure_features")
#========================================================================================================================
# 5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable
#    for each activity and each subject.
# 5.1 Load subject data
sub_train<-read.table(paste(dir_path, "train/subject_train.txt", sep = ""),
header = FALSE)
sub_test<-read.table(paste(dir_path, "test/subject_test.txt", sep = ""),
header = FALSE)
subjects<-rbind(sub_train, sub_test)
# 5.2 Include subjects in the measured_values data frame
measured_values<-cbind(measured_values, subjects = subjects$V1)
# 5.3 Get the column_names for every measure variables
measure_var_names<-names(measured_values)[1:(ncol(measured_values)-2)]
# 5.3 Create a new data set with the averages of each variable for each activity and each subject.
measured_averages<-measured_values %>%
group_by(activities, subjects) %>%
summarize_at(measure_var_names, funs(mean(., na.rm = TRUE)))
#Delete temporary vectors
rm("sub_train", "sub_test", "subjects", "measure_var_names", "dir_path")
View(measured_averages)
#========================================================================================================================
?write.table
write.table(measured_averages,
file = "tidy_measured_averages.txt",
row.name=FALSE)
getwd()
library(swirl)
swirl()
sample(colors(), 10)
pal<-colorRamp(c("red", "blue"))
pal(0)
pal(1)
pal(seq(0, 1, len =6))
p1<-colorRampPalette(c("red","blue"))
p1(2)
p1(6)
0xcc
p2<-colorRampPalette(c("red","yellow"))
p2(2)
p2(10)
showMe(p1(20))
showMe(p2(20))
showMe(p2(2))
p1
?fun
}
?name <- function(variables) {
}
?rgb
p3<-colorRampPalette(c("blue", "green"), alpha = 0.5)
p3(5)
plot(x, y, pch = 19, col = rgb(0, 0.5, 0.5))
plot(x, y, pch = 19, col = rgb(0, 0.5, 0.5, 0.3))
cols<-brewer.pal(3, "BuGn")
showMe()
showMe
showMe(cols)
pal<-colorRampPalette(cols)
showMe(pal(20))
image(volcano, col = pal(20))
image(volcano, col = p1(20))
str(mpg)
qplot(displ, hwy, data = mpg)
qplot(displ, hwy, data = mpg, color = drv)
qplot(displ, hwy, data = mpg, color = drv, geom = c("point", "smooth"))
qplot(y = hwym data = mpg, color = drv)
qplot(y = hwy, data = mpg, color = drv)
myhigh
qplot(drv, hwy, data = mpg, geom = "boxplot")
qplot(drv, hwy, data = mpg, geom = "boxplot", color = manufacturer)
qplot(hwy, data = mpg, fill = drv)
qplot(displ, hwy, data = mpg, facets = . ~ drv)
qplot(hwy, data = mpg, facets = drv ~ . . , binwidth = 2)
qplot(hwy, data = mpg, facets = drv ~ . , binwidth = 2)
qplot(displ, hwy, data = mpg, geom = c("point", "smooth"), facets = .~drv)
g<-ggplot(mpg, aes(displ, hwy))
summary(g)
g+geom_point()
geom_smooth()
g+geom_point()+geom_smooth()
g+geom_point()+geom_smooth(method = "lm")
g+geom_point()+geom_smooth(method = "lm")+facet_grid(.~drv)
g+geom_point()+geom_smooth(method = "lm")+facet_grid(.~drv)+ggtitle("Swirl Rules!")
g+geom_pont(color = "pink", size = 4, alpha = 0.5)
g+geom_point(color = "pink", size = 4, alpha = 0.5)
g+geom_point(size = 4, alpha = 0.5, aes(color = drv))
g+geom_point(size = 4, alpha = 0.5, aes(color = drv))+ labs(title = "Swirl Rules!")+ labs(x = "Displacement", y = "Hwy Mileage")
g+geom_point(aes(color = drv))+ labs(title = "Swirl Rules!")+ labs(x = "Displacement", y = "Hwy Mileage")
g+geom_point(size = 2, alpha = 0.5, aes(color = drv))+ geom_smooth(size = 4, linetype = 3, method = "lm", se = FALSE)
g+geom_point(aes(color = drv), theme_bw(base_family = "Times"))
g+geom_point(aes(color = drv))+ theme_bw(base_family = "Times")
plot(-myx, myy, type = "l", ylim = c(-3,3))
plot(myx, myy, type = "l", ylim = c(-3,3))
g<-ggplot(testdat, aes(x = myx, y = myy))
g+ geom_lime(0)
g+ geom_line(0)
g+ geom_line()
g+ geom_line() +ylim(-3,3)
g+ geom_line() + coord_cartesian(ylim = c(-3,3))
g<-ggplot(data = mpg, aes(x = displ, y = hwy, color = factor(year)))
g+geom_point()
g+geom_point()+facet_grid(drv~cyl, margins = TRUE)
g+geom_point()+facet_grid(drv~cyl, margins = TRUE)+geom_smooth(method = "lm", se = FALSE, size = 2, color = "black")
g+geom_point()+facet_grid(drv~cyl, margins = TRUE)+geom_smooth(method = "lm", se = FALSE, size = 2, color = "black")+ labs(x = "Displacement", y = "Highway Mileage", title = "Swirl Rules!")
str(diamonths)
str(diamonds)
qplot(price, data = diamonds)
range(diamonds$price)
qplot(price, data = diamonds, binwidth = 18497/30)
brk
count
counts
qplot(price, data = diamonds, binwidth = 18497/30, fill = cut)
qplot(price, data = diamonds, geom = "density")
qplot(price, data = diamonds, geom = "density", color = cut)
qplot(carat, price, data= diamonds)
qplot(carat, price, data= diamonds, shape = cut)
qplot(carat, price, data= diamonds, color = cut)
qplot(carat, price, data= diamonds, color = cut, geom_smooth(set = "lm"))
qplot(carat, price, data= diamonds, color = cut, set = "lm")
qplot(carat,price,data=diamonds, color=cut) + geom_smooth(method="lm")
qplot(carat,price,data=diamonds, color=cut, facets = .~cut) + geom_smooth(method="lm")
g<-ggplot(data = diamonds, aes(depth, price))
summary(G)
summary(g)
g+geom_point(alpha = 1/3)
cutpoints<-quantile(data = diamonds$carat, seq(0,1,length =4), na.rm = TRUE)
cutpoints<-quantile(diamonds$carat, seq(0,1,length =4), na.rm = TRUE)
cutpoints
diamonds$car2<-cut(diamonds$carat, cutpoints)
g<-ggplot(data = diamonds, aes(depth, price))
g+geom_point(alpha = 1/3, facet_grid(cut~car2))
g+geom_point(alpha = 1/3)+ facet_grid(cut~car2)
diamonds[myd,]
g+geom_point(alpha = 1/3)+ facet_grid(cut~car2)+ geom_smooth(method = "lm", size = 3, color = "pink")
ggplot(diamonds, aes(carat, price))+geom_boxplot()+facet_grid(.~cut)
dist(dataFrame)
hc<-hclust(distxy)
plot(hc)
plot(as.dendrogram(hc))
abline(h =1.5, col = "blue")
abline(h =0.4, col = "red")
5
11
12
abline(h =0.05, col = "green")
dist(dFsm)
hc
heatmap(dataMatrix, col = cm.colors(25))
heatmap(mt)
mt
plot(denmt)
distmt
swirl()
cmat
points(cx, cy, col = c("red", "orange", "purple"), pch = 3, cex = 2, lwd = 2)
mdist(x, y, cx, cy)
apply(distTmp, 2, which.min)
points(x, y, pch = 19, cex = 2,  col - cols1[newClust])
points(x, y, pch = 19, cex = 2,  col = cols1[newClust])
tapply(x, newClust, mean)
tapply(y, newClust, mean)
points(newCx, newCy, col = cols1, pch = 8, cex = 2, lwd = 2)
mdist(x,y,newCx, newCy)
apply(distTmp2, 2, which.min)
points(x, y, pch = 19, cex = 2, col = cols1[newClust2])
tapply(x, newClust2, mean)
tapply(y, newClust2, mean)
points(finalCx, finalCy, col = cols1, pch = 9, cex= 2, lwd = 2)
kmeans(dataFrame, centers = 3)
kmObj$iter
plot(x, y, col = kmObj$centers, pch = 19, cex = 2)
plot(x, y, col = kmObj$cluster, pch = 19, cex = 2)
points(kmObj$centers, col = c("black", "red", "green"), pch = 3, cex = 3, lwd = 3)
plot(x,y, col = kmeans(dataFrame,6)$cluster, pch = 19, dex = 2)
plot(x,y, col = kmeans(dataFrame,6)$cluster, pch = 19, cex = 2)
plot(x,y, col = kmeans(dataFrame,6)$cluster, pch = 19, cex = 2)
plot(x,y, col = kmeans(dataFrame,6)$cluster, pch = 19, cex = 2)
head(dataMatrix)
heatmap(dataMatrix)
myedit("addPatt.R")
source("addPatt.R", local = TRUE)
heatmap(dataMatrix)
mat
svd(mat)
matu %*% t
matu %*% diag %*% t
matu %*% diag
matu %*% diag %*% t(matv)
svd(scale(mat))
prcomp(scale(mat))
svd1<-svd(dataMatrix)
svd1v[,1]
svd1$v[,1]
svd$d
svd1$d
head(constantMatrix)
svd2
svd2$d
svd2['d', 'u']
svd2[['d', 'u']]
svd2$v[,2]
svd2$v[,1:2]
svd2$d
dim(faceData)
a1<-svd1$u[,1]
a1 <- (svd1$u[,1] * svd1$d[1]) %*% t(svd1$v[,1])
a1
myImage(a1)
library(swirl)
swirl()
a2 <- (svd1$u[,2] * `diag<-`(svd1$d[2])) %*% t(svd1$v[,2])
a2 <- (svd1$u[,2] * `diag<-`(svd1$d[1:2])) %*% t(svd1$v[,2])
?diag
a2 <- svd1$u[,2] %*% `diag(svd1$d[1:2]) %*% t(svd1$v[,2])
)
)
a2 <- svd1$u[,2] %*% `diag(svd1$d[1:2]) %*% t(svd1$v[,2])
a2 <- svd1$u[1:2] %*% `diag(svd1$d[1:2]) %*% t(svd1$v[1:2])
a2 <- (svd1$u[1:2] %*% `diag(svd1$d[1:2])) %*% t(svd1$v[1:2])
a2 <- (svd1$u[1:2] %*% `diag(svd1$d[1:2])) %*% t(svd1$v[1:2])
head(constantMatrix)
a2 <- svd1$u[,1:2] %*% `diag(svd1$d[1:2]) %*% t(svd1$v[,1:2])
a2 <- svd1$u[,1:2] %*% diag(svd1$d[1:2]) %*% t(svd1$v[,1:2])
a2 <- svd1$u[,1:2] %*% diag(svd1$d[1:2]) %*% t(svd1$v[,1:2])
myImage(a2)
myImage(svd1$u[,1:5] %*% diag(svd1$d[1:5]) %*% t(svd1$v[,1:5]))
myImage(svd1$u[,1:10] %*% diag(svd1$d[1:10]) %*% t(svd1$v[,1:10]))
dim(ssd)
names(ssd['562'], ssd['563'])
?names
names(ssd[,-2])
names(ssd[562:563])
table(ssd$subject)
sum(table(ssd$subject))
table(ssd$activity)
sub1<-subset(ssd, subject = 1)
sub1<-subset(ssd, subject == 1)
dim(sub1)
names(sub1[1:12])
myedit("showXY.R")
showMe(c(1:6))
mdist<- dist(sub1[, 1:3])
hclustering<-hclust(mdist)
myplclust(hclustering, lab.col = unclass(sub1$activity))
mdist<-dist(sub1[, 10:12])
hclustering<-hclust(mdist)
myplclust(hclustering, lab.col = unclass(sub1$activity))
svd1<- svd(scale(sub1[, -c(562, 563)]))
dim(svd$u)
dim(svd1$u)
maxCon<-which.max(svd1$v)
maxCon<-which.max(svd1$v[,2])
mdist<-dist(sub1[, c(10:12, maxCon)])
hclustering<-hclust(mdist)
myplclust(hclustering, lab.col = unclass(sub1$activity))
names(sub1[maxCon])
kClust<-kmeans(sub1[, -c(562, 563)], centers = 6)
table(kClust$cluster, sub1$activity)
kClust<-kmeans(sub1[, -c(562, 563)], centers = 6, nstart = 100)
table(kClust$cluster, sub1$activity)
dim(kClust$centers)
laying<-which(kClust$size==29)
plot(kClust$centers[laying, 1:12], pch = 19, ylab = "Laying Cluster")
names(sub1[, 1:3])
walkdown<-which(kClust$size ==49)
plot(kClust$centers[walkdown, 1:12], pch = 19, ylab = "Walkdown Cluster")
unlink('~/datasciencecoursera/05Reproducible Research/Course Project 2/PA1_template_cache', recursive = TRUE)
getwd()
setwd("OneDrive/Documents/datasciencecoursera/05Reproducible Research/Course Project 2/")
#Load data
PAM<-read.csv("activity/activity.csv")
#Convert date from "factor" to "Date" type
PAM$date<-as.Date(PAM$date, format = "%Y-%m-%d")
library(dplyr)
PAM_DLY<-na.omit(PAM) %>%
group_by(date) %>%
summarise(Sum = sum(steps, na.rm = TRUE))
hist(PAM_DLY$Sum, main = "Total number of steps taken each day", xlab = "Total steps")
options(scipen=1, digits=2)
Mean_Dly<-mean(PAM_DLY$Sum)
Median_Dly<-median(PAM_DLY$Sum)
PAM_AVG<-PAM %>%
group_by(interval) %>%
summarise(Avg = mean(steps, na.rm = TRUE))
PAM_AVG<-PAM %>%
group_by(interval) %>%
summarise(Avg = mean(steps, na.rm = TRUE))
with(PAM_AVG, plot(interval, Avg,
type = "l",
xlab = "Intervals",
ylab = "Average number of steps taken per day"))
PAM_AVG_Max<-PAM_AVG$interval[PAM_AVG$Avg == max(PAM_AVG$Avg)]
nulls<-sum(is.na(PAM))
PAM_NoNulls<-PAM %>%
inner_join(PAM_AVG) %>%
mutate(steps = coalesce(steps, Avg)) %>%
select(steps, date, interval)
head(PAM_NoNulls)
PAM_DLY1<-PAM_NoNulls %>%
group_by(date) %>%
summarise(Sum = sum(steps))
hist(PAM_DLY1$Sum, main = "Total number of steps taken each day", xlab = "Total steps")
Mean_Dly1<-mean(PAM_DLY1$Sum)
Median_Dly1<-median(PAM_DLY1$Sum)
WeekDays<- c('Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday')
PAM$IsWeekEnd <- factor((weekdays(PAM$date) %in% WeekDays),
levels=c(FALSE, TRUE),
labels=c('weekend', 'weekday'))
library(lattice)
xyplot(steps ~ interval | IsWeekend,
data = PAM,
layout= c(1,2),
type = "l")
library(lattice)
xyplot(steps ~ interval | IsWeekEnd,
data = PAM,
layout= c(1,2),
type = "l")
